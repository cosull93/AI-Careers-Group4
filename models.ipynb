{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a436d104",
   "metadata": {},
   "source": [
    "# Regression, Classification, and Topic Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34009d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de82860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JobPostingsAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_path = \"lightcast_job_postings.csv\"\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .csv(file_path)\n",
    "#df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc460",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e78f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+----------------------------------+----------+\n",
      "|TITLE_CLEAN                                            |LOT_V6_SPECIALIZED_OCCUPATION_NAME|IS_AI_ROLE|\n",
      "+-------------------------------------------------------+----------------------------------+----------+\n",
      "|data engineering lead data technology data analytics ai|Data Analyst                      |1         |\n",
      "|ai ml governance analyst                               |Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai|Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai|Data Analyst                      |1         |\n",
      "|ai ml governance analyst                               |Data Analyst                      |1         |\n",
      "+-------------------------------------------------------+----------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, when\n",
    "\n",
    "# AI-related keywords\n",
    "ai_pattern = r'\\b(ai|artificial intelligence|machine learning|deep learning|generative ai|neural network|nlp|computer vision)\\b'\n",
    "\n",
    "# Create AI Role flag (1 = AI job, 0 = Non-AI job)\n",
    "df = df.withColumn(\n",
    "    \"IS_AI_ROLE\",\n",
    "    when(\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(ai_pattern) |\n",
    "        lower(col(\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")).rlike(ai_pattern),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "df.select(\n",
    "    \"TITLE_CLEAN\",\n",
    "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
    "    \"IS_AI_ROLE\"\n",
    ").orderBy(col(\"IS_AI_ROLE\").desc()) \\\n",
    " .show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4d3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Missing Value Treatment\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, when, isnan, count, expr, median\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate overall median salary\n",
    "overall_median_salarly = df.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\n",
    "\n",
    "median_by_employment_type = df.groupBy(\"EMPLOYMENT_TYPE\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type\"))\n",
    "median_by_employment_type_name = df.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type_name\"))\n",
    "\n",
    "# Join median values back to the original dataframe\n",
    "df_salary_imputed = df.join(median_by_employment_type, on=\"EMPLOYMENT_TYPE\", how = \"left\").join(median_by_employment_type_name, on=\"EMPLOYMENT_TYPE_NAME\", how = \"left\")\n",
    "\n",
    "\n",
    "# Replace missing SALARY values\n",
    "df_salary_imputed=df_salary_imputed.withColumn(\"SALARY\", when(col(\"SALARY\").isNull(), \n",
    "                                when (col(\"median_salary_emp_type\").isNotNull(), col(\"median_salary_emp_type\"))\n",
    "                                .when(col(\"median_salary_emp_type_name\").isNotNull(), col(\"median_salary_emp_type_name\"))\n",
    "                                .otherwise(overall_median_salarly)\n",
    ").otherwise(col(\"SALARY\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1cc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, pow\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import BooleanType, StringType, IntegerType\n",
    "from pyspark.sql.functions import regexp_replace, trim\n",
    "\n",
    "# Drop rows with NA values \n",
    "regression_df = df_salary_imputed.dropna(subset=[\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"median_salary_emp_type_name\", \"IS_AI_ROLE\", \n",
    "]).select(\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"median_salary_emp_type_name\", \"IS_AI_ROLE\", \n",
    "   \n",
    ")\n",
    "\n",
    "# Cast Duration to integer\n",
    "regression_df = regression_df.withColumn(\"DURATION\", col(\"DURATION\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6f589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+---------------------+--------------------+----------------+--------+-------------+-------------------+---------------------------+----------+\n",
      "|SALARY  |MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|EDUCATION_LEVELS_NAME|EMPLOYMENT_TYPE_NAME|REMOTE_TYPE_NAME|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|median_salary_emp_type_name|IS_AI_ROLE|\n",
      "+--------+--------------------+--------------------+---------------------+--------------------+----------------+--------+-------------+-------------------+---------------------------+----------+\n",
      "|116500.0|2                   |2                   |\"Bachelor's degree\"  |Fulltime            |Undefined       |6       |0            |0                  |116500                     |0         |\n",
      "|116500.0|7                   |7                   |\"No Education Listed\"|Fulltime            |Undefined       |18      |0            |1                  |116500                     |0         |\n",
      "|116500.0|1                   |1                   |\"No Education Listed\"|Fulltime            |Undefined       |8       |0            |1                  |116500                     |0         |\n",
      "|116500.0|1                   |1                   |\"Bachelor's degree\"  |Fulltime            |Undefined       |32      |0            |0                  |116500                     |0         |\n",
      "|131100.0|2                   |2                   |\"Bachelor's degree\"  |Fulltime            |Undefined       |11      |0            |0                  |116500                     |0         |\n",
      "+--------+--------------------+--------------------+---------------------+--------------------+----------------+--------+-------------+-------------------+---------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns\n",
    "categorical_cols = [ \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"]\n",
    "\n",
    "# Cast boolean columns to integer\n",
    "regression_df = regression_df.withColumn(\"IS_INTERNSHIP\", col(\"IS_INTERNSHIP\").cast(IntegerType()))\n",
    "regression_df = regression_df.withColumn(\"COMPANY_IS_STAFFING\", col(\"COMPANY_IS_STAFFING\").cast(IntegerType()))\n",
    "\n",
    "\n",
    "# Clean Remote Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"REMOTE_TYPE_NAME\",\n",
    "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Premise\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On Premise\")\n",
    "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Employment Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EMPLOYMENT_TYPE_NAME\",\n",
    "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Parttime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Fulltime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n",
    "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Education Levels\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EDUCATION_LEVELS_NAME\",\n",
    "    trim(regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), r\"[\\[\\]\\n]\", \"\"))\n",
    ")\n",
    "\n",
    "\n",
    "regression_df.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
