{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a436d104",
   "metadata": {},
   "source": [
    "# Regression, Classification, and Topic Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34009d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5de82860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JobPostingsAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_path = \"lightcast_job_postings.csv\"\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .csv(file_path)\n",
    "#df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc460",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96e78f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1167:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+--------------------------------------------------------------+----------------------------------+----------+\n",
      "|TITLE_CLEAN                                             |TITLE_RAW                                                     |LOT_V6_SPECIALIZED_OCCUPATION_NAME|IS_AI_ROLE|\n",
      "+--------------------------------------------------------+--------------------------------------------------------------+----------------------------------+----------+\n",
      "|sr bi analyst data scientist                            |Sr BI Analyst/Data Scientist                                  |Data Analyst                      |1         |\n",
      "|ai ml governance analyst                                |AI/ML Governance Analyst                                      |Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai |Data Engineering Lead, Data & Technology, Data Analytics & AI |Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai |Data Engineering Lead, Data & Technology, Data Analytics & AI |Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai |Data Engineering Lead, Data & Technology, Data Analytics & AI |Data Analyst                      |1         |\n",
      "|ai ml governance analyst                                |AI/ML Governance Analyst                                      |Data Analyst                      |1         |\n",
      "|ai ml governance analyst                                |AI/ML Governance Analyst                                      |Data Analyst                      |1         |\n",
      "|ai ml governance analyst                                |AI/ML Governance Analyst                                      |Data Analyst                      |1         |\n",
      "|principal data science analyst gen ai                   |Principal Data Science Analyst - GEN AI                       |Data Analyst                      |1         |\n",
      "|lead data analyst data scientist analytics bi consultant|Lead Data Analyst / Data Scientist / Analytics / BI Consultant|Data Analyst                      |1         |\n",
      "+--------------------------------------------------------+--------------------------------------------------------------+----------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, when\n",
    "\n",
    "# Create AI Role flag with VERY specific patterns\n",
    "df = df.withColumn(\n",
    "    \"IS_AI_ROLE\",\n",
    "    when(\n",
    "        # Specific AI/ML terms (these are safe)\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'\\b(machine learning|deep learning|artificial intelligence|generative ai|neural network|computer vision|data scientist)\\b') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'\\b(machine learning|deep learning|artificial intelligence|generative ai|neural network|computer vision|data scientist)\\b') |\n",
    "        lower(col(\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")).rlike(r'\\b(machine learning|deep learning|artificial intelligence|generative ai|neural network|computer vision|data scientist)\\b') |\n",
    "        \n",
    "        # AI as a standalone word (with spaces or punctuation around it)\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'(\\s|^)ai(\\s|$|/|-)') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'(\\s|^)ai(\\s|$|/|-)') |\n",
    "        lower(col(\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")).rlike(r'(\\s|^)ai(\\s|$|/|-)') |\n",
    "        \n",
    "        # ML Engineer/Scientist variants\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'\\bml\\s+(engineer|scientist|developer|analyst)\\b') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'\\bml\\s+(engineer|scientist|developer|analyst)\\b') |\n",
    "        \n",
    "        # NLP specifically\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'\\bnlp\\b') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'\\bnlp\\b'),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Verify\n",
    "df.select(\n",
    "    \"TITLE_CLEAN\",\n",
    "    \"TITLE_RAW\",\n",
    "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
    "    \"IS_AI_ROLE\"\n",
    ").orderBy(col(\"IS_AI_ROLE\").desc()) \\\n",
    " .show(10, truncate=False)\n",
    "\n",
    "\n",
    "#df.groupBy(\"IS_AI_ROLE\").count().orderBy(\"IS_AI_ROLE\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f4d3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Missing Value Treatment\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, when, isnan, count, expr, median\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate overall median salary\n",
    "overall_median_salarly = df.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\n",
    "\n",
    "median_by_employment_type = df.groupBy(\"EMPLOYMENT_TYPE\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type\"))\n",
    "median_by_employment_type_name = df.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type_name\"))\n",
    "\n",
    "# Join median values back to the original dataframe\n",
    "df_salary_imputed = df.join(median_by_employment_type, on=\"EMPLOYMENT_TYPE\", how = \"left\").join(median_by_employment_type_name, on=\"EMPLOYMENT_TYPE_NAME\", how = \"left\")\n",
    "\n",
    "\n",
    "# Replace missing SALARY values\n",
    "df_salary_imputed=df_salary_imputed.withColumn(\"SALARY\", when(col(\"SALARY\").isNull(), \n",
    "                                when (col(\"median_salary_emp_type\").isNotNull(), col(\"median_salary_emp_type\"))\n",
    "                                .when(col(\"median_salary_emp_type_name\").isNotNull(), col(\"median_salary_emp_type_name\"))\n",
    "                                .otherwise(overall_median_salarly)\n",
    ").otherwise(col(\"SALARY\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e963fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, pow\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import BooleanType, StringType, IntegerType\n",
    "from pyspark.sql.functions import regexp_replace, trim\n",
    "\n",
    "# Drop rows with NA values \n",
    "regression_df = df_salary_imputed.dropna(subset=[\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"IS_AI_ROLE\", \n",
    "]).select(\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"IS_AI_ROLE\", \n",
    "   \n",
    ")\n",
    "\n",
    "# Cast Duration to integer\n",
    "regression_df = regression_df.withColumn(\"DURATION\", col(\"DURATION\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be6f589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+---------------------+--------------------+----------------+--------+-------------+-------------------+----------+\n",
      "|SALARY  |MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|EDUCATION_LEVELS_NAME|EMPLOYMENT_TYPE_NAME|REMOTE_TYPE_NAME|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|IS_AI_ROLE|\n",
      "+--------+--------------------+--------------------+---------------------+--------------------+----------------+--------+-------------+-------------------+----------+\n",
      "|116500.0|2                   |2                   |\"Bachelor's degree\"  |Fulltime            |Undefined       |6       |0            |0                  |0         |\n",
      "|116500.0|7                   |7                   |\"No Education Listed\"|Fulltime            |Undefined       |18      |0            |1                  |0         |\n",
      "|116500.0|1                   |1                   |\"No Education Listed\"|Fulltime            |Undefined       |8       |0            |1                  |0         |\n",
      "|116500.0|1                   |1                   |\"Bachelor's degree\"  |Fulltime            |Undefined       |32      |0            |0                  |0         |\n",
      "|131100.0|2                   |2                   |\"Bachelor's degree\"  |Fulltime            |Undefined       |11      |0            |0                  |0         |\n",
      "+--------+--------------------+--------------------+---------------------+--------------------+----------------+--------+-------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns\n",
    "categorical_cols = [ \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"]\n",
    "\n",
    "# Cast boolean columns to integer\n",
    "regression_df = regression_df.withColumn(\"IS_INTERNSHIP\", col(\"IS_INTERNSHIP\").cast(IntegerType()))\n",
    "regression_df = regression_df.withColumn(\"COMPANY_IS_STAFFING\", col(\"COMPANY_IS_STAFFING\").cast(IntegerType()))\n",
    "\n",
    "\n",
    "# Clean Remote Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"REMOTE_TYPE_NAME\",\n",
    "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Premise\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On Premise\")\n",
    "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Employment Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EMPLOYMENT_TYPE_NAME\",\n",
    "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Parttime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Fulltime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n",
    "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Education Levels\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EDUCATION_LEVELS_NAME\",\n",
    "    trim(regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), r\"[\\[\\]\\n]\", \"\"))\n",
    ")\n",
    "\n",
    "\n",
    "regression_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef33c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------------------------------------------------+\n",
      "|SALARY  |features                                                     |\n",
      "+--------+-------------------------------------------------------------+\n",
      "|116500.0|(29,[0,1,2,4,22,24,27,28],[2.0,2.0,6.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|116500.0|(29,[0,1,2,5,22,24,27],[7.0,7.0,18.0,1.0,1.0,1.0,1.0])       |\n",
      "|116500.0|(29,[0,1,2,5,22,24,27],[1.0,1.0,8.0,1.0,1.0,1.0,1.0])        |\n",
      "|116500.0|(29,[0,1,2,4,22,24,27,28],[1.0,1.0,32.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|131100.0|(29,[0,1,2,4,22,24,27,28],[2.0,2.0,11.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+--------+-------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Index and One-Hot Encode\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"skip\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n",
    "\n",
    "#Assemble base features\n",
    "assembler = VectorAssembler(\n",
    "       inputCols=[\"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \n",
    "                  \"DURATION\", \"IS_AI_ROLE\"] + [f\"{col}_vec\" for col in categorical_cols],\n",
    "       outputCol=\"features\"\n",
    "   )\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "regression_data =  pipeline.fit(regression_df).transform(regression_df)\n",
    "regression_data.select(\"SALARY\",\"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "130afc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4070, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1264:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "regression_train, regression_test = regression_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print((regression_data.count(), len(regression_data.columns)))\n",
    "print((regression_train.count(), len(regression_train.columns)))\n",
    "print((regression_test.count(), len(regression_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "814f9f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/09 21:29:25 WARN Instrumentation: [64cbbb93] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/10/09 21:29:34 WARN Instrumentation: [64cbbb93] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "[Stage 1311:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22058.821158120867\n",
      "R²: 0.1915025455889091\n",
      "MAE: 15535.593012196921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Train Multiple Linear Regression Model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"SALARY\")\n",
    "lr_model = lr.fit(regression_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr_model.transform(regression_test)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f38a37d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1318:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------------------+--------------------+\n",
      "|IS_AI_ROLE|job_count| avg_actual_salary|avg_predicted_salary|\n",
      "+----------+---------+------------------+--------------------+\n",
      "|         0|      955|113290.49214659687|  111576.33820922484|\n",
      "|         1|       14|111894.64285714286|  117446.94495596984|\n",
      "+----------+---------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.select(\"SALARY\", \"prediction\", \"IS_AI_ROLE\") \\\n",
    "    .groupBy(\"IS_AI_ROLE\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"job_count\"),\n",
    "        F.avg(\"SALARY\").alias(\"avg_actual_salary\"),\n",
    "        F.avg(\"prediction\").alias(\"avg_predicted_salary\")\n",
    "    ).orderBy(\"IS_AI_ROLE\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e2008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
