{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a436d104",
   "metadata": {},
   "source": [
    "# Regression, Classification, and Topic Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34009d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de82860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JobPostingsAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_path = \"lightcast_job_postings.csv\"\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .csv(file_path)\n",
    "#df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc460",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96e78f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+----------------------------------+----------+\n",
      "|TITLE_CLEAN                                            |LOT_V6_SPECIALIZED_OCCUPATION_NAME|IS_AI_ROLE|\n",
      "+-------------------------------------------------------+----------------------------------+----------+\n",
      "|data engineering lead data technology data analytics ai|Data Analyst                      |1         |\n",
      "|ai ml governance analyst                               |Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai|Data Analyst                      |1         |\n",
      "|data engineering lead data technology data analytics ai|Data Analyst                      |1         |\n",
      "|ai ml governance analyst                               |Data Analyst                      |1         |\n",
      "+-------------------------------------------------------+----------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, when\n",
    "\n",
    "# AI-related keywords\n",
    "ai_pattern = r'\\b(ai|artificial intelligence|machine learning|deep learning|generative ai|neural network|nlp|computer vision)\\b'\n",
    "\n",
    "# Create AI Role flag (1 = AI job, 0 = Non-AI job)\n",
    "df = df.withColumn(\n",
    "    \"IS_AI_ROLE\",\n",
    "    when(\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(ai_pattern) |\n",
    "        lower(col(\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")).rlike(ai_pattern),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "df.select(\n",
    "    \"TITLE_CLEAN\",\n",
    "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
    "    \"IS_AI_ROLE\"\n",
    ").orderBy(col(\"IS_AI_ROLE\").desc()) \\\n",
    " .show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4d3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Missing Value Treatment\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, when, isnan, count, expr, median\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate overall median salary\n",
    "overall_median_salarly = df.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\n",
    "\n",
    "median_by_employment_type = df.groupBy(\"EMPLOYMENT_TYPE\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type\"))\n",
    "median_by_employment_type_name = df.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type_name\"))\n",
    "\n",
    "# Join median values back to the original dataframe\n",
    "df_salary_imputed = df.join(median_by_employment_type, on=\"EMPLOYMENT_TYPE\", how = \"left\").join(median_by_employment_type_name, on=\"EMPLOYMENT_TYPE_NAME\", how = \"left\")\n",
    "\n",
    "\n",
    "# Replace missing SALARY values\n",
    "df_salary_imputed=df_salary_imputed.withColumn(\"SALARY\", when(col(\"SALARY\").isNull(), \n",
    "                                when (col(\"median_salary_emp_type\").isNotNull(), col(\"median_salary_emp_type\"))\n",
    "                                .when(col(\"median_salary_emp_type_name\").isNotNull(), col(\"median_salary_emp_type_name\"))\n",
    "                                .otherwise(overall_median_salarly)\n",
    ").otherwise(col(\"SALARY\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c1cc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, pow\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import BooleanType, StringType, IntegerType\n",
    "from pyspark.sql.functions import regexp_replace, trim\n",
    "\n",
    "# Drop rows with NA values \n",
    "regression_df = df_salary_imputed.dropna(subset=[\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"median_salary_emp_type_name\", \"IS_AI_ROLE\", \n",
    "]).select(\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"median_salary_emp_type_name\", \"IS_AI_ROLE\", \n",
    "   \n",
    ")\n",
    "\n",
    "# Cast Duration to integer\n",
    "regression_df = regression_df.withColumn(\"DURATION\", col(\"DURATION\").cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6f589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+---------------------------------------+--------------------+----------------+--------+-------------+-------------------+---------------------------+----------+\n",
      "|SALARY  |MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|EDUCATION_LEVELS_NAME                  |EMPLOYMENT_TYPE_NAME|REMOTE_TYPE_NAME|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|median_salary_emp_type_name|IS_AI_ROLE|\n",
      "+--------+--------------------+--------------------+---------------------------------------+--------------------+----------------+--------+-------------+-------------------+---------------------------+----------+\n",
      "|117500.0|3                   |3                   |\"Bachelor's degree\",  \"Master's degree\"|Flexible            |Undefined       |14      |0            |0                  |100000                     |0         |\n",
      "|100000.0|3                   |3                   |\"Bachelor's degree\"                    |Flexible            |Undefined       |42      |0            |0                  |100000                     |0         |\n",
      "|100000.0|3                   |3                   |\"Bachelor's degree\"                    |Flexible            |Undefined       |20      |0            |0                  |100000                     |0         |\n",
      "|100000.0|1                   |1                   |\"High school or GED\"                   |Flexible            |Undefined       |42      |0            |0                  |100000                     |0         |\n",
      "|162050.0|5                   |5                   |\"No Education Listed\"                  |Flexible            |On Premise      |33      |0            |0                  |100000                     |0         |\n",
      "+--------+--------------------+--------------------+---------------------------------------+--------------------+----------------+--------+-------------+-------------------+---------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Categorical columns\n",
    "categorical_cols = [ \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"]\n",
    "\n",
    "# Cast boolean columns to integer\n",
    "regression_df = regression_df.withColumn(\"IS_INTERNSHIP\", col(\"IS_INTERNSHIP\").cast(IntegerType()))\n",
    "regression_df = regression_df.withColumn(\"COMPANY_IS_STAFFING\", col(\"COMPANY_IS_STAFFING\").cast(IntegerType()))\n",
    "\n",
    "\n",
    "# Clean Remote Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"REMOTE_TYPE_NAME\",\n",
    "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Premise\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On Premise\")\n",
    "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Employment Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EMPLOYMENT_TYPE_NAME\",\n",
    "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Parttime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Fulltime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n",
    "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Education Levels\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EDUCATION_LEVELS_NAME\",\n",
    "    trim(regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), r\"[\\[\\]\\n]\", \"\"))\n",
    ")\n",
    "\n",
    "\n",
    "regression_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef33c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 244:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------+\n",
      "|SALARY  |features                                              |\n",
      "+--------+------------------------------------------------------+\n",
      "|117500.0|(29,[0,1,2,6,24,27,28],[3.0,3.0,14.0,1.0,1.0,1.0,1.0])|\n",
      "|100000.0|(29,[0,1,2,4,24,27,28],[3.0,3.0,42.0,1.0,1.0,1.0,1.0])|\n",
      "|100000.0|(29,[0,1,2,4,24,27,28],[3.0,3.0,20.0,1.0,1.0,1.0,1.0])|\n",
      "|100000.0|(29,[0,1,2,9,24,27,28],[1.0,1.0,42.0,1.0,1.0,1.0,1.0])|\n",
      "|162050.0|(29,[0,1,2,5,27,28],[5.0,5.0,33.0,1.0,1.0,1.0])       |\n",
      "+--------+------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Index and One-Hot Encode\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"skip\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n",
    "\n",
    "#Assemble base features\n",
    "assembler = VectorAssembler(\n",
    "       inputCols=[\"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \n",
    "                  \"DURATION\", \"IS_AI_ROLE\"] + [f\"{col}_vec\" for col in categorical_cols],\n",
    "       outputCol=\"features\"\n",
    "   )\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "regression_data =  pipeline.fit(regression_df).transform(regression_df)\n",
    "regression_data.select(\"SALARY\",\"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "130afc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4070, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 276:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "regression_train, regression_test = regression_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print((regression_data.count(), len(regression_data.columns)))\n",
    "print((regression_train.count(), len(regression_train.columns)))\n",
    "print((regression_test.count(), len(regression_test.columns)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
