{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a436d104",
   "metadata": {},
   "source": [
    "# Regression, Classification, and Topic Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34009d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de82860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JobPostingsAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_path = \"lightcast_job_postings.csv\"\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .csv(file_path)\n",
    "#df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc460",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e78f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 186:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------------------------+----------+\n",
      "|         TITLE_CLEAN|           TITLE_RAW|LOT_V6_SPECIALIZED_OCCUPATION_NAME|IS_AI_ROLE|\n",
      "+--------------------+--------------------+----------------------------------+----------+\n",
      "|sr bi analyst dat...|Sr BI Analyst/Dat...|                      Data Analyst|         1|\n",
      "|ai ml governance ...|AI/ML Governance ...|                      Data Analyst|         1|\n",
      "|data engineering ...|Data Engineering ...|                      Data Analyst|         1|\n",
      "|data engineering ...|Data Engineering ...|                      Data Analyst|         1|\n",
      "|data engineering ...|Data Engineering ...|                      Data Analyst|         1|\n",
      "+--------------------+--------------------+----------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, when\n",
    "\n",
    "# Create AI Role flag with VERY specific patterns\n",
    "df = df.withColumn(\n",
    "    \"IS_AI_ROLE\",\n",
    "    when(\n",
    "        # Specific AI/ML terms (these are safe)\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'\\b(machine learning|deep learning|artificial intelligence|generative ai|neural network|computer vision|data scientist)\\b') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'\\b(machine learning|deep learning|artificial intelligence|generative ai|neural network|computer vision|data scientist)\\b') |\n",
    "        lower(col(\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")).rlike(r'\\b(machine learning|deep learning|artificial intelligence|generative ai|neural network|computer vision|data scientist)\\b') |\n",
    "        \n",
    "        # AI as a standalone word (with spaces or punctuation around it)\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'(\\s|^)ai(\\s|$|/|-)') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'(\\s|^)ai(\\s|$|/|-)') |\n",
    "        lower(col(\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")).rlike(r'(\\s|^)ai(\\s|$|/|-)') |\n",
    "        \n",
    "        # ML Engineer/Scientist variants\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'\\bml\\s+(engineer|scientist|developer|analyst)\\b') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'\\bml\\s+(engineer|scientist|developer|analyst)\\b') |\n",
    "        \n",
    "        # NLP specifically\n",
    "        lower(col(\"TITLE_CLEAN\")).rlike(r'\\bnlp\\b') |\n",
    "        lower(col(\"TITLE_RAW\")).rlike(r'\\bnlp\\b'),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Verify\n",
    "df.select(\n",
    "    \"TITLE_CLEAN\",\n",
    "    \"TITLE_RAW\",\n",
    "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
    "    \"IS_AI_ROLE\"\n",
    ").orderBy(col(\"IS_AI_ROLE\").desc()) \\\n",
    " .show(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4d3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Missing Value Treatment\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, when, isnan, count, expr, median\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate overall median salary\n",
    "overall_median_salarly = df.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\n",
    "\n",
    "median_by_employment_type = df.groupBy(\"EMPLOYMENT_TYPE\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type\"))\n",
    "median_by_employment_type_name = df.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type_name\"))\n",
    "\n",
    "# Join median values back to the original dataframe\n",
    "df_salary_imputed = df.join(median_by_employment_type, on=\"EMPLOYMENT_TYPE\", how = \"left\").join(median_by_employment_type_name, on=\"EMPLOYMENT_TYPE_NAME\", how = \"left\")\n",
    "\n",
    "\n",
    "# Replace missing SALARY values\n",
    "df_salary_imputed=df_salary_imputed.withColumn(\"SALARY\", when(col(\"SALARY\").isNull(), \n",
    "                                when (col(\"median_salary_emp_type\").isNotNull(), col(\"median_salary_emp_type\"))\n",
    "                                .when(col(\"median_salary_emp_type_name\").isNotNull(), col(\"median_salary_emp_type_name\"))\n",
    "                                .otherwise(overall_median_salarly)\n",
    ").otherwise(col(\"SALARY\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963fcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, trim, regexp_replace, coalesce, lit\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "regression_df = df_salary_imputed.dropna(subset=[\"SALARY\"])\n",
    "\n",
    "# Impute numeric columns with median values\n",
    "for c in [\"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \"DURATION\"]:\n",
    "    med = df_salary_imputed.approxQuantile(c, [0.5], 0.01)[0]\n",
    "    if med is not None:\n",
    "        regression_df = regression_df.na.fill({c: med})\n",
    "\n",
    "# Cast duration to integer \n",
    "regression_df = regression_df.withColumn(\"DURATION\", col(\"DURATION\").cast(IntegerType()))\n",
    "\n",
    "# Cast boolean columns to integers (0/1)\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"IS_INTERNSHIP\", coalesce(col(\"IS_INTERNSHIP\").cast(IntegerType()), lit(0))\n",
    ")\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"COMPANY_IS_STAFFING\", coalesce(col(\"COMPANY_IS_STAFFING\").cast(IntegerType()), lit(0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6f589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 216:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----------------------------------+--------------------+----------------+--------+-------------+-------------------+----------+\n",
      "|SALARY  |MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|EDUCATION_LEVELS_NAME              |EMPLOYMENT_TYPE_NAME|REMOTE_TYPE_NAME|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|IS_AI_ROLE|\n",
      "+--------+--------------------+--------------------+-----------------------------------+--------------------+----------------+--------+-------------+-------------------+----------+\n",
      "|92500.0 |5                   |3                   |No Education Listed                |Flexible            |Undefined       |15      |0            |0                  |0         |\n",
      "|100000.0|5                   |3                   |No Education Listed                |Flexible            |Undefined       |18      |1            |0                  |0         |\n",
      "|222000.0|10                  |3                   |Bachelor's degree,  Master's degree|Flexible            |Undefined       |18      |0            |0                  |0         |\n",
      "|101798.0|3                   |3                   |Bachelor's degree                  |Flexible            |Undefined       |18      |0            |0                  |0         |\n",
      "|100000.0|5                   |3                   |Bachelor's degree                  |Flexible            |Undefined       |18      |1            |0                  |0         |\n",
      "+--------+--------------------+--------------------+-----------------------------------+--------------------+----------------+--------+-------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Clean Remote Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"REMOTE_TYPE_NAME\",\n",
    "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Premise\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
    "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On Premise\")\n",
    "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Employment Type Name\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EMPLOYMENT_TYPE_NAME\",\n",
    "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Parttime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Fulltime\")\n",
    "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n",
    "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
    ")\n",
    "\n",
    "# Clean Education Levels\n",
    "regression_df = regression_df.withColumn(\n",
    "    \"EDUCATION_LEVELS_NAME\",\n",
    "    trim(regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), r\"[\\[\\]\\n\\\"]\", \"\"))\n",
    ")\n",
    "regression_df = regression_df.fillna({\"EDUCATION_LEVELS_NAME\": \"No Education Listed\"})\n",
    "\n",
    "regression_df = regression_df.select(\n",
    "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\",\n",
    "    \"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\",\n",
    "    \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\", \"IS_AI_ROLE\"\n",
    ")\n",
    "\n",
    "regression_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef33c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ai_df = regression_df.filter(col(\"IS_AI_ROLE\") == 1)\n",
    "non_ai_df = regression_df.filter(col(\"IS_AI_ROLE\") == 0)\n",
    "\n",
    "if ai_df.count() > 0:\n",
    "    ratio = non_ai_df.count() / ai_df.count()\n",
    "    ai_df_balanced = ai_df.sample(withReplacement=True, fraction=ratio, seed=42)\n",
    "    regression_df = non_ai_df.union(ai_df_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cd19de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\"EDUCATION_LEVELS_NAME\", \"EMPLOYMENT_TYPE_NAME\",\n",
    "                    \"REMOTE_TYPE_NAME\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"skip\") for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_vec\") for c in categorical_cols]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \"DURATION\", \"IS_AI_ROLE\"] +\n",
    "              [f\"{c}_vec\" for c in categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "regression_data = pipeline.fit(regression_df).transform(regression_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130afc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4070, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1264:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "regression_train, regression_test = regression_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print((regression_data.count(), len(regression_data.columns)))\n",
    "print((regression_train.count(), len(regression_train.columns)))\n",
    "print((regression_test.count(), len(regression_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "814f9f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/09 21:29:25 WARN Instrumentation: [64cbbb93] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/10/09 21:29:34 WARN Instrumentation: [64cbbb93] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "[Stage 1311:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22058.821158120867\n",
      "R²: 0.1915025455889091\n",
      "MAE: 15535.593012196921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Train Multiple Linear Regression Model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"SALARY\")\n",
    "lr_model = lr.fit(regression_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr_model.transform(regression_test)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f38a37d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1318:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------------------+--------------------+\n",
      "|IS_AI_ROLE|job_count| avg_actual_salary|avg_predicted_salary|\n",
      "+----------+---------+------------------+--------------------+\n",
      "|         0|      955|113290.49214659687|  111576.33820922484|\n",
      "|         1|       14|111894.64285714286|  117446.94495596984|\n",
      "+----------+---------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.select(\"SALARY\", \"prediction\", \"IS_AI_ROLE\") \\\n",
    "    .groupBy(\"IS_AI_ROLE\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"job_count\"),\n",
    "        F.avg(\"SALARY\").alias(\"avg_actual_salary\"),\n",
    "        F.avg(\"prediction\").alias(\"avg_predicted_salary\")\n",
    "    ).orderBy(\"IS_AI_ROLE\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431383fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
